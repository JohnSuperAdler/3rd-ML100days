{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### DNN module\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.applications import ResNet50\n",
    "from keras.optimizers import Adagrad, RMSprop, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Common moldule\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Path\n",
    "\n",
    "#train_db = 'database/combined_train_mx_240.npy'\n",
    "#label_db = 'database/combined_label_mx_240.npy'\n",
    "\n",
    "#flower_li = list(map(os.path.basename, glob.glob('database/image_data/train/*')))\n",
    "#flower_mapping = {flower_li[i]: i for i in range(5)}\n",
    "\n",
    "#print(flower_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load data\n",
    "\n",
    "#flower_data   = np.load(train_db).astype('uint8')\n",
    "#flower_target = np.load(label_db).astype('uint8')\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(flower_data, flower_target, test_size=0.2, random_state=9527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Dimenssion check\n",
    "\n",
    "#(np.shape(x_train), np.shape(x_test), np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 5 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 20 # 訓練的 epochs 數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "#print('x_train shape:', x_train.shape)\n",
    "#print(x_train.shape[0], 'train samples')\n",
    "#print(x_test.shape[0], 'test samples')\n",
    "#x_train = x_train.astype('float32')\n",
    "#x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = to_categorical(y_train, num_classes)\n",
    "#y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 120, 120, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 120, 120, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 116, 116, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 116, 116, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 58, 58, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 58, 58, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 58, 58, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 54, 54, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 27, 27, 32)        51232     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 23, 23, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1982976   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 2,244,197\n",
      "Trainable params: 2,244,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), padding='same', input_shape=(120,120,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "'''\n",
    "model.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "'''\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_generator = ImageDataGenerator(rotation_range=20,\n",
    "                                       rescale=1./255,\n",
    "                                       featurewise_center=True,\n",
    "                                       featurewise_std_normalization=True,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       data_format='channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2823 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = augment_generator.flow_from_directory('database/image_data/train',\n",
    "                                                        target_size=(120, 120),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2823 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = augment_generator.flow_from_directory('database/image_data/train',\n",
    "                                                        target_size=(120, 120),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 120, 120, 3)\n",
      "labels batch shape: (20, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 20s 144ms/step - loss: 1.5931 - accuracy: 0.2929 - val_loss: 1.9794 - val_accuracy: 0.2840\n",
      "Epoch 2/40\n",
      "141/141 [==============================] - 19s 138ms/step - loss: 1.4513 - accuracy: 0.4217 - val_loss: 1.8394 - val_accuracy: 0.3500\n",
      "Epoch 3/40\n",
      "141/141 [==============================] - 19s 132ms/step - loss: 1.2900 - accuracy: 0.4620 - val_loss: 0.8502 - val_accuracy: 0.4822\n",
      "Epoch 4/40\n",
      "141/141 [==============================] - 19s 133ms/step - loss: 1.1943 - accuracy: 0.5309 - val_loss: 1.1473 - val_accuracy: 0.5020\n",
      "Epoch 5/40\n",
      "141/141 [==============================] - 19s 133ms/step - loss: 1.1437 - accuracy: 0.5605 - val_loss: 0.7946 - val_accuracy: 0.6120\n",
      "Epoch 6/40\n",
      "141/141 [==============================] - 18s 131ms/step - loss: 1.0544 - accuracy: 0.5965 - val_loss: 0.7146 - val_accuracy: 0.6256\n",
      "Epoch 7/40\n",
      "141/141 [==============================] - 17s 123ms/step - loss: 1.0405 - accuracy: 0.6093 - val_loss: 0.9548 - val_accuracy: 0.6450\n",
      "Epoch 8/40\n",
      "141/141 [==============================] - 18s 129ms/step - loss: 1.0263 - accuracy: 0.6233 - val_loss: 0.8967 - val_accuracy: 0.6650\n",
      "Epoch 9/40\n",
      "141/141 [==============================] - 19s 134ms/step - loss: 0.9773 - accuracy: 0.6354 - val_loss: 0.5785 - val_accuracy: 0.5951\n",
      "Epoch 10/40\n",
      "141/141 [==============================] - 18s 131ms/step - loss: 0.9559 - accuracy: 0.6475 - val_loss: 1.0012 - val_accuracy: 0.6450\n",
      "Epoch 11/40\n",
      "141/141 [==============================] - 18s 131ms/step - loss: 0.9109 - accuracy: 0.6568 - val_loss: 0.6493 - val_accuracy: 0.6500\n",
      "Epoch 12/40\n",
      "141/141 [==============================] - 17s 123ms/step - loss: 0.9346 - accuracy: 0.6522 - val_loss: 0.4420 - val_accuracy: 0.7009\n",
      "Epoch 13/40\n",
      "141/141 [==============================] - 19s 135ms/step - loss: 0.9066 - accuracy: 0.6625 - val_loss: 1.0748 - val_accuracy: 0.6740\n",
      "Epoch 14/40\n",
      "141/141 [==============================] - 18s 126ms/step - loss: 0.8951 - accuracy: 0.6800 - val_loss: 0.9824 - val_accuracy: 0.6780\n",
      "Epoch 15/40\n",
      "141/141 [==============================] - 18s 126ms/step - loss: 0.8947 - accuracy: 0.6689 - val_loss: 0.7756 - val_accuracy: 0.6989\n",
      "Epoch 16/40\n",
      "141/141 [==============================] - 17s 122ms/step - loss: 0.8942 - accuracy: 0.6836 - val_loss: 1.0607 - val_accuracy: 0.6500\n",
      "Epoch 17/40\n",
      "141/141 [==============================] - 17s 124ms/step - loss: 0.8767 - accuracy: 0.6771 - val_loss: 0.4675 - val_accuracy: 0.7110\n",
      "Epoch 18/40\n",
      "141/141 [==============================] - 19s 136ms/step - loss: 0.8820 - accuracy: 0.6821 - val_loss: 0.7866 - val_accuracy: 0.6938\n",
      "Epoch 19/40\n",
      "141/141 [==============================] - 15s 107ms/step - loss: 0.8754 - accuracy: 0.6743 - val_loss: 0.7928 - val_accuracy: 0.6910\n",
      "Epoch 20/40\n",
      "141/141 [==============================] - 15s 110ms/step - loss: 0.8710 - accuracy: 0.6900 - val_loss: 0.7560 - val_accuracy: 0.7019\n",
      "Epoch 21/40\n",
      "141/141 [==============================] - 15s 109ms/step - loss: 0.8491 - accuracy: 0.7182 - val_loss: 0.6499 - val_accuracy: 0.6880\n",
      "Epoch 22/40\n",
      "141/141 [==============================] - 15s 110ms/step - loss: 0.8851 - accuracy: 0.6882 - val_loss: 1.1221 - val_accuracy: 0.6800\n",
      "Epoch 23/40\n",
      "141/141 [==============================] - 15s 107ms/step - loss: 0.9100 - accuracy: 0.6878 - val_loss: 0.5012 - val_accuracy: 0.6918\n",
      "Epoch 24/40\n",
      "141/141 [==============================] - 15s 110ms/step - loss: 0.8825 - accuracy: 0.6864 - val_loss: 0.9472 - val_accuracy: 0.6360\n",
      "Epoch 25/40\n",
      "141/141 [==============================] - 16s 112ms/step - loss: 0.8759 - accuracy: 0.7000 - val_loss: 0.8870 - val_accuracy: 0.6720\n",
      "Epoch 26/40\n",
      "141/141 [==============================] - 18s 124ms/step - loss: 0.8999 - accuracy: 0.6713 - val_loss: 0.5655 - val_accuracy: 0.6796\n",
      "Epoch 27/40\n",
      "141/141 [==============================] - 15s 108ms/step - loss: 0.8622 - accuracy: 0.6949 - val_loss: 0.8133 - val_accuracy: 0.7040\n",
      "Epoch 28/40\n",
      "141/141 [==============================] - 15s 108ms/step - loss: 0.8814 - accuracy: 0.6903 - val_loss: 0.9595 - val_accuracy: 0.7520\n",
      "Epoch 29/40\n",
      "141/141 [==============================] - 15s 109ms/step - loss: 0.8815 - accuracy: 0.6889 - val_loss: 0.7792 - val_accuracy: 0.7284\n",
      "Epoch 30/40\n",
      "141/141 [==============================] - 15s 106ms/step - loss: 0.9460 - accuracy: 0.6753 - val_loss: 0.8677 - val_accuracy: 0.7450\n",
      "Epoch 31/40\n",
      "141/141 [==============================] - 17s 123ms/step - loss: 1.2050 - accuracy: 0.6536 - val_loss: 0.5757 - val_accuracy: 0.6220\n",
      "Epoch 32/40\n",
      "141/141 [==============================] - 15s 107ms/step - loss: 1.0892 - accuracy: 0.6393 - val_loss: 0.9517 - val_accuracy: 0.7121\n",
      "Epoch 33/40\n",
      "141/141 [==============================] - 16s 116ms/step - loss: 0.9777 - accuracy: 0.6667 - val_loss: 0.7084 - val_accuracy: 0.6770\n",
      "Epoch 34/40\n",
      "141/141 [==============================] - 17s 123ms/step - loss: 0.9917 - accuracy: 0.6497 - val_loss: 0.9096 - val_accuracy: 0.7070\n",
      "Epoch 35/40\n",
      "141/141 [==============================] - 18s 129ms/step - loss: 1.1355 - accuracy: 0.6238 - val_loss: 2.2531 - val_accuracy: 0.7131\n",
      "Epoch 36/40\n",
      "141/141 [==============================] - 15s 105ms/step - loss: 0.9773 - accuracy: 0.6579 - val_loss: 0.9015 - val_accuracy: 0.6420\n",
      "Epoch 37/40\n",
      "141/141 [==============================] - 15s 106ms/step - loss: 0.9854 - accuracy: 0.6600 - val_loss: 0.7574 - val_accuracy: 0.7457\n",
      "Epoch 38/40\n",
      "141/141 [==============================] - 15s 105ms/step - loss: 1.0832 - accuracy: 0.6318 - val_loss: 0.7146 - val_accuracy: 0.6680\n",
      "Epoch 39/40\n",
      "141/141 [==============================] - 15s 107ms/step - loss: 1.1053 - accuracy: 0.6309 - val_loss: 0.7505 - val_accuracy: 0.6910\n",
      "Epoch 40/40\n",
      "141/141 [==============================] - 17s 124ms/step - loss: 1.2871 - accuracy: 0.6400 - val_loss: 0.8477 - val_accuracy: 0.6317\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=int(2823/20), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/STD_datagen_1230_010.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Test on unknown sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['database/image_data/test\\\\0028624c49b3e0610ff9f1d111f5d532.jpg',\n",
       " 'database/image_data/test\\\\002c30700185b7971369258b438070d5.jpg',\n",
       " 'database/image_data/test\\\\00852f4f666acecd0c0d140365b42efd.jpg',\n",
       " 'database/image_data/test\\\\00c08828fce04e360c732cac01edad9e.jpg',\n",
       " 'database/image_data/test\\\\00d366e7877b6a78b104b57d67b60e6b.jpg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_unknown = glob.glob('database/image_data/test/*')\n",
    "path_unknown[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleRGI3d(input_mx, resize_to, dtype='float32'):\n",
    "    # Ref: 10 3-A-7\n",
    "    # Ver. 2.1\n",
    "    # input_mx : numpy array, the original target matrix\n",
    "    # resize_to: list or tuple with 3 int inside\n",
    "    a, b, c = np.shape(input_mx)\n",
    "    p, q, r = resize_to\n",
    "    z_grid = np.linspace(0, p - 1, a)\n",
    "    y_grid = np.linspace(0, q - 1, b)\n",
    "    x_grid = np.linspace(0, r - 1, c)\n",
    "    RGI = RegularGridInterpolator((z_grid, y_grid, x_grid), input_mx)\n",
    "    z_grid_t2 = np.arange(p)\n",
    "    y_grid_t2 = np.arange(q)\n",
    "    x_grid_t2 = np.arange(r)\n",
    "    meshgrid_para = np.meshgrid(z_grid_t2, y_grid_t2, x_grid_t2)\n",
    "    RGI_mesh_mx = RGI((meshgrid_para[0], meshgrid_para[1], meshgrid_para[2]))\n",
    "    RGI_mx = np.transpose(RGI_mesh_mx, axes=[1, 0, 2]).astype(dtype)\n",
    "    return RGI_mx\n",
    "\n",
    "def happy_time(start,stop):\n",
    "    process_time = round(stop - start)\n",
    "    ss = process_time % 60\n",
    "    mm = process_time // 60 % 60\n",
    "    hh = process_time // 3600\n",
    "    duration = \"Process time == {}s == {}H {}m {}s\".format(process_time,hh,mm,ss)\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 files done. Process time == 3s == 0H 0m 3s\n",
      "400 files done. Process time == 6s == 0H 0m 6s\n",
      "600 files done. Process time == 9s == 0H 0m 9s\n",
      "800 files done. Process time == 12s == 0H 0m 12s\n",
      "1000 files done. Process time == 15s == 0H 0m 15s\n",
      "1200 files done. Process time == 18s == 0H 0m 18s\n",
      "1400 files done. Process time == 21s == 0H 0m 21s\n",
      "1600 files done. Process time == 24s == 0H 0m 24s\n",
      "1800 files done. Process time == 27s == 0H 0m 27s\n",
      "2000 files done. Process time == 31s == 0H 0m 31s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "id_li = []\n",
    "flower_class = []\n",
    "loop_start = time.time()\n",
    "\n",
    "for j in range(len(path_unknown)):\n",
    "    serial = os.path.basename(path_unknown[j])[:-4]\n",
    "    temp_pic = np.asarray(Image.open(path_unknown[j]))\n",
    "    temp_pic = resampleRGI3d(temp_pic, (120, 120, 3))\n",
    "    temp_shape = np.shape(temp_pic)\n",
    "    temp_pic = np.expand_dims(temp_pic, axis = 0)\n",
    "    pred = model.predict(temp_pic)[0]\n",
    "    id_li.append(serial)\n",
    "    flower_class.append(list(pred).index(max(pred)))\n",
    "    if (j+1) % 200 == 0:\n",
    "        print(j+1, 'files done.', happy_time(loop_start, time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flower_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0028624c49b3e0610ff9f1d111f5d532</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002c30700185b7971369258b438070d5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00852f4f666acecd0c0d140365b42efd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c08828fce04e360c732cac01edad9e</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00d366e7877b6a78b104b57d67b60e6b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>ff7eac29b6d7a33fbd8009677c3e9c58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>ffbc32a7b67dfe72b8d35d4b1b35fd6c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>ffea1f275c05accb0a6bfd1203620c7e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>ffeb2a1cf53464b6af937ab8af0c2946</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>ffefcc68e2e7eed8b17b0b5b0f740538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  flower_class\n",
       "0     0028624c49b3e0610ff9f1d111f5d532             4\n",
       "1     002c30700185b7971369258b438070d5             4\n",
       "2     00852f4f666acecd0c0d140365b42efd             4\n",
       "3     00c08828fce04e360c732cac01edad9e             4\n",
       "4     00d366e7877b6a78b104b57d67b60e6b             4\n",
       "...                                ...           ...\n",
       "1995  ff7eac29b6d7a33fbd8009677c3e9c58             1\n",
       "1996  ffbc32a7b67dfe72b8d35d4b1b35fd6c             3\n",
       "1997  ffea1f275c05accb0a6bfd1203620c7e             0\n",
       "1998  ffeb2a1cf53464b6af937ab8af0c2946             3\n",
       "1999  ffefcc68e2e7eed8b17b0b5b0f740538             4\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result_df = pd.DataFrame(columns=['id', 'flower_class'])\n",
    "pred_result_df['id'] = id_li\n",
    "pred_result_df['flower_class'] = flower_class\n",
    "pred_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    443\n",
       "1    417\n",
       "2    234\n",
       "3    265\n",
       "4    641\n",
       "Name: flower_class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result_df['flower_class'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result_df.to_csv('model/pred_result_STD_datagen_1230_010.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#####\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
