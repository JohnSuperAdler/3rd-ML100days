{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### DNN module\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.applications import ResNet50\n",
    "from keras.optimizers import Adagrad, RMSprop, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Common moldule\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Path\n",
    "\n",
    "#train_db = 'database/combined_train_mx_240.npy'\n",
    "#label_db = 'database/combined_label_mx_240.npy'\n",
    "\n",
    "#flower_li = list(map(os.path.basename, glob.glob('database/image_data/train/*')))\n",
    "#flower_mapping = {flower_li[i]: i for i in range(5)}\n",
    "\n",
    "#print(flower_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load data\n",
    "\n",
    "#flower_data   = np.load(train_db).astype('uint8')\n",
    "#flower_target = np.load(label_db).astype('uint8')\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(flower_data, flower_target, test_size=0.2, random_state=9527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Dimenssion check\n",
    "\n",
    "#(np.shape(x_train), np.shape(x_test), np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 5 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 20 # 訓練的 epochs 數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "#print('x_train shape:', x_train.shape)\n",
    "#print(x_train.shape[0], 'train samples')\n",
    "#print(x_test.shape[0], 'test samples')\n",
    "#x_train = x_train.astype('float32')\n",
    "#x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = to_categorical(y_train, num_classes)\n",
    "#y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 120, 120, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 120, 120, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 116, 116, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 116, 116, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 58, 58, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 58, 58, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 58, 58, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 54, 54, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 27, 27, 32)        51232     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 23, 23, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1982976   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 2,244,197\n",
      "Trainable params: 2,244,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), padding='same', input_shape=(120,120,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "'''\n",
    "model.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "'''\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_generator = ImageDataGenerator(rotation_range=20,\n",
    "                                       rescale=1./255,\n",
    "                                       featurewise_center=True,\n",
    "                                       featurewise_std_normalization=True,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       data_format='channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2823 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = augment_generator.flow_from_directory('database/image_data/train',\n",
    "                                                        target_size=(120, 120),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2823 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = augment_generator.flow_from_directory('database/image_data/train',\n",
    "                                                        target_size=(120, 120),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 120, 120, 3)\n",
      "labels batch shape: (20, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 21s 146ms/step - loss: 1.5429 - accuracy: 0.3115 - val_loss: 1.4139 - val_accuracy: 0.3960\n",
      "Epoch 2/20\n",
      "141/141 [==============================] - 19s 136ms/step - loss: 1.3265 - accuracy: 0.4367 - val_loss: 1.2169 - val_accuracy: 0.5230\n",
      "Epoch 3/20\n",
      "141/141 [==============================] - 19s 132ms/step - loss: 1.2502 - accuracy: 0.4945 - val_loss: 1.2001 - val_accuracy: 0.5615\n",
      "Epoch 4/20\n",
      "141/141 [==============================] - 18s 128ms/step - loss: 1.1773 - accuracy: 0.5473 - val_loss: 0.9206 - val_accuracy: 0.5790\n",
      "Epoch 5/20\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 1.1534 - accuracy: 0.5623 - val_loss: 0.9292 - val_accuracy: 0.6380\n",
      "Epoch 6/20\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 1.0778 - accuracy: 0.5908 - val_loss: 0.6309 - val_accuracy: 0.5605\n",
      "Epoch 7/20\n",
      "141/141 [==============================] - 15s 109ms/step - loss: 1.0466 - accuracy: 0.6118 - val_loss: 1.1476 - val_accuracy: 0.6540\n",
      "Epoch 8/20\n",
      "141/141 [==============================] - 16s 113ms/step - loss: 1.0289 - accuracy: 0.6101 - val_loss: 0.9200 - val_accuracy: 0.5930\n",
      "Epoch 9/20\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.9893 - accuracy: 0.6258 - val_loss: 0.7738 - val_accuracy: 0.6826\n",
      "Epoch 10/20\n",
      "141/141 [==============================] - 16s 110ms/step - loss: 0.9774 - accuracy: 0.6443 - val_loss: 0.8218 - val_accuracy: 0.6280\n",
      "Epoch 11/20\n",
      "141/141 [==============================] - 18s 126ms/step - loss: 0.9455 - accuracy: 0.6600 - val_loss: 0.8677 - val_accuracy: 0.6600\n",
      "Epoch 12/20\n",
      "141/141 [==============================] - 16s 114ms/step - loss: 0.9336 - accuracy: 0.6725 - val_loss: 0.9618 - val_accuracy: 0.5738\n",
      "Epoch 13/20\n",
      "141/141 [==============================] - 16s 111ms/step - loss: 0.9416 - accuracy: 0.6604 - val_loss: 0.5441 - val_accuracy: 0.7370\n",
      "Epoch 14/20\n",
      "141/141 [==============================] - 15s 108ms/step - loss: 0.8858 - accuracy: 0.6707 - val_loss: 0.8850 - val_accuracy: 0.7300\n",
      "Epoch 15/20\n",
      "141/141 [==============================] - 15s 107ms/step - loss: 0.9413 - accuracy: 0.6650 - val_loss: 0.7744 - val_accuracy: 0.6724\n",
      "Epoch 16/20\n",
      "141/141 [==============================] - 15s 107ms/step - loss: 0.8531 - accuracy: 0.6761 - val_loss: 0.7410 - val_accuracy: 0.7140\n",
      "Epoch 17/20\n",
      "141/141 [==============================] - 15s 109ms/step - loss: 0.9010 - accuracy: 0.6679 - val_loss: 1.0556 - val_accuracy: 0.6770\n",
      "Epoch 18/20\n",
      "141/141 [==============================] - 17s 118ms/step - loss: 0.8739 - accuracy: 0.6882 - val_loss: 0.9021 - val_accuracy: 0.7030\n",
      "Epoch 19/20\n",
      "141/141 [==============================] - 15s 108ms/step - loss: 0.8778 - accuracy: 0.6793 - val_loss: 2.1503 - val_accuracy: 0.7090\n",
      "Epoch 20/20\n",
      "141/141 [==============================] - 16s 110ms/step - loss: 0.8796 - accuracy: 0.6828 - val_loss: 0.8491 - val_accuracy: 0.7040\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=int(2823/20), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/STD_datagen_1230_009.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Test on unknown sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['database/image_data/test\\\\0028624c49b3e0610ff9f1d111f5d532.jpg',\n",
       " 'database/image_data/test\\\\002c30700185b7971369258b438070d5.jpg',\n",
       " 'database/image_data/test\\\\00852f4f666acecd0c0d140365b42efd.jpg',\n",
       " 'database/image_data/test\\\\00c08828fce04e360c732cac01edad9e.jpg',\n",
       " 'database/image_data/test\\\\00d366e7877b6a78b104b57d67b60e6b.jpg']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_unknown = glob.glob('database/image_data/test/*')\n",
    "path_unknown[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleRGI3d(input_mx, resize_to, dtype='float32'):\n",
    "    # Ref: 10 3-A-7\n",
    "    # Ver. 2.1\n",
    "    # input_mx : numpy array, the original target matrix\n",
    "    # resize_to: list or tuple with 3 int inside\n",
    "    a, b, c = np.shape(input_mx)\n",
    "    p, q, r = resize_to\n",
    "    z_grid = np.linspace(0, p - 1, a)\n",
    "    y_grid = np.linspace(0, q - 1, b)\n",
    "    x_grid = np.linspace(0, r - 1, c)\n",
    "    RGI = RegularGridInterpolator((z_grid, y_grid, x_grid), input_mx)\n",
    "    z_grid_t2 = np.arange(p)\n",
    "    y_grid_t2 = np.arange(q)\n",
    "    x_grid_t2 = np.arange(r)\n",
    "    meshgrid_para = np.meshgrid(z_grid_t2, y_grid_t2, x_grid_t2)\n",
    "    RGI_mesh_mx = RGI((meshgrid_para[0], meshgrid_para[1], meshgrid_para[2]))\n",
    "    RGI_mx = np.transpose(RGI_mesh_mx, axes=[1, 0, 2]).astype(dtype)\n",
    "    return RGI_mx\n",
    "\n",
    "def happy_time(start,stop):\n",
    "    process_time = round(stop - start)\n",
    "    ss = process_time % 60\n",
    "    mm = process_time // 60 % 60\n",
    "    hh = process_time // 3600\n",
    "    duration = \"Process time == {}s == {}H {}m {}s\".format(process_time,hh,mm,ss)\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 files done. Process time == 3s == 0H 0m 3s\n",
      "400 files done. Process time == 6s == 0H 0m 6s\n",
      "600 files done. Process time == 10s == 0H 0m 10s\n",
      "800 files done. Process time == 13s == 0H 0m 13s\n",
      "1000 files done. Process time == 16s == 0H 0m 16s\n",
      "1200 files done. Process time == 19s == 0H 0m 19s\n",
      "1400 files done. Process time == 22s == 0H 0m 22s\n",
      "1600 files done. Process time == 26s == 0H 0m 26s\n",
      "1800 files done. Process time == 29s == 0H 0m 29s\n",
      "2000 files done. Process time == 32s == 0H 0m 32s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "id_li = []\n",
    "flower_class = []\n",
    "loop_start = time.time()\n",
    "\n",
    "for j in range(len(path_unknown)):\n",
    "    serial = os.path.basename(path_unknown[j])[:-4]\n",
    "    temp_pic = np.asarray(Image.open(path_unknown[j]))\n",
    "    temp_pic = resampleRGI3d(temp_pic, (120, 120, 3))\n",
    "    temp_shape = np.shape(temp_pic)\n",
    "    temp_pic = np.expand_dims(temp_pic, axis = 0)\n",
    "    pred = model.predict(temp_pic)[0]\n",
    "    id_li.append(serial)\n",
    "    flower_class.append(list(pred).index(max(pred)))\n",
    "    if (j+1) % 200 == 0:\n",
    "        print(j+1, 'files done.', happy_time(loop_start, time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flower_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0028624c49b3e0610ff9f1d111f5d532</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002c30700185b7971369258b438070d5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00852f4f666acecd0c0d140365b42efd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c08828fce04e360c732cac01edad9e</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00d366e7877b6a78b104b57d67b60e6b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>ff7eac29b6d7a33fbd8009677c3e9c58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>ffbc32a7b67dfe72b8d35d4b1b35fd6c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>ffea1f275c05accb0a6bfd1203620c7e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>ffeb2a1cf53464b6af937ab8af0c2946</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>ffefcc68e2e7eed8b17b0b5b0f740538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  flower_class\n",
       "0     0028624c49b3e0610ff9f1d111f5d532             4\n",
       "1     002c30700185b7971369258b438070d5             4\n",
       "2     00852f4f666acecd0c0d140365b42efd             4\n",
       "3     00c08828fce04e360c732cac01edad9e             4\n",
       "4     00d366e7877b6a78b104b57d67b60e6b             4\n",
       "...                                ...           ...\n",
       "1995  ff7eac29b6d7a33fbd8009677c3e9c58             1\n",
       "1996  ffbc32a7b67dfe72b8d35d4b1b35fd6c             3\n",
       "1997  ffea1f275c05accb0a6bfd1203620c7e             0\n",
       "1998  ffeb2a1cf53464b6af937ab8af0c2946             3\n",
       "1999  ffefcc68e2e7eed8b17b0b5b0f740538             4\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result_df = pd.DataFrame(columns=['id', 'flower_class'])\n",
    "pred_result_df['id'] = id_li\n",
    "pred_result_df['flower_class'] = flower_class\n",
    "pred_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    360\n",
       "1     47\n",
       "2    111\n",
       "3    745\n",
       "4    737\n",
       "Name: flower_class, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result_df['flower_class'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result_df.to_csv('model/pred_result_STD_datagen_1230_009-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#####\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
