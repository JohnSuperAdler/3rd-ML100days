{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### DNN module\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop, Adagrad, Adam, SGD\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from keras import backend as K\n",
    "#from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Common moldule\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Control Panel\n",
    "\n",
    "fn_serial   = '016'\n",
    "batch_size  = 64\n",
    "num_classes = 5\n",
    "epochs      = 50\n",
    "pic_size    = 120\n",
    "pool_size   = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total config: 72\n"
     ]
    }
   ],
   "source": [
    "##### Selection\n",
    "\n",
    "Conv2D_size = [(3, 3), (5, 5), (7, 7)]\n",
    "drop_out    = [0., 0.1]\n",
    "l1_ratio    = [1e-4, 1e-8]\n",
    "optimizer   = [Adam(lr=0.01),\n",
    "               Adam(lr=0.001),\n",
    "               RMSprop(lr=0.01),\n",
    "               RMSprop(lr=0.001),\n",
    "               SGD(lr=0.01, momentum=0.95),\n",
    "               SGD(lr=0.001, momentum=0.95),\n",
    "              ]\n",
    "\n",
    "total_item = len(Conv2D_size) * len(drop_out) * len(l1_ratio) * len(optimizer)\n",
    "print('Total config:', total_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, Conv2D_size, pic_size, l1_ratio, pool_size, drop_out_ratio):\n",
    "    model = Sequential()\n",
    "    model.name=model_name\n",
    "    model.add(Conv2D(32, Conv2D_size, padding='same', input_shape=(pic_size, pic_size, 3), kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Conv2D(128, Conv2D_size, padding='same', kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Conv2D(64, Conv2D_size, padding='same', kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Conv2D(32, Conv2D_size, padding='same', kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compile(optimizer):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleRGI3d(input_mx, resize_to, dtype='float32'):\n",
    "    # Ref: 10 3-A-7\n",
    "    # Ver. 2.1\n",
    "    # input_mx : numpy array, the original target matrix\n",
    "    # resize_to: list or tuple with 3 int inside\n",
    "    a, b, c = np.shape(input_mx)\n",
    "    p, q, r = resize_to\n",
    "    z_grid = np.linspace(0, p - 1, a)\n",
    "    y_grid = np.linspace(0, q - 1, b)\n",
    "    x_grid = np.linspace(0, r - 1, c)\n",
    "    RGI = RegularGridInterpolator((z_grid, y_grid, x_grid), input_mx)\n",
    "    z_grid_t2 = np.arange(p)\n",
    "    y_grid_t2 = np.arange(q)\n",
    "    x_grid_t2 = np.arange(r)\n",
    "    meshgrid_para = np.meshgrid(z_grid_t2, y_grid_t2, x_grid_t2)\n",
    "    RGI_mesh_mx = RGI((meshgrid_para[0], meshgrid_para[1], meshgrid_para[2]))\n",
    "    RGI_mx = np.transpose(RGI_mesh_mx, axes=[1, 0, 2]).astype(dtype)\n",
    "    return RGI_mx\n",
    "\n",
    "def happy_time(start,stop):\n",
    "    process_time = round(stop - start)\n",
    "    ss = process_time % 60\n",
    "    mm = process_time // 60 % 60\n",
    "    hh = process_time // 3600\n",
    "    duration = \"Process time == {}s == {}H {}m {}s\".format(process_time,hh,mm,ss)\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unknown = glob.glob('database/image_data/test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dict: 2000\n"
     ]
    }
   ],
   "source": [
    "unknown_dict = {}\n",
    "\n",
    "for j in range(len(path_unknown)):\n",
    "    serial = os.path.basename(path_unknown[j])[:-4]\n",
    "    temp_pic = np.asarray(Image.open(path_unknown[j]))\n",
    "    temp_pic = resampleRGI3d(temp_pic, (pic_size, pic_size, 3))\n",
    "    temp_shape = np.shape(temp_pic)\n",
    "    temp_pic = np.expand_dims(temp_pic, axis = 0)\n",
    "    unknown_dict[serial] = temp_pic\n",
    "\n",
    "print('Length of dict:', len(list(unknown_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ImageDataGenerator\n",
    "\n",
    "augment_generator = ImageDataGenerator(\n",
    "                                       rotation_range=20,\n",
    "                                       rescale=1./255,\n",
    "                                       #featurewise_center=True,\n",
    "                                       #featurewise_std_normalization=True,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       #data_format='channels_last'\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2323 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n",
      "data batch shape: (64, 120, 120, 3)\n",
      "labels batch shape: (64, 5)\n"
     ]
    }
   ],
   "source": [
    "##### Generator for train and validation\n",
    "\n",
    "train_generator = augment_generator.flow_from_directory('database/image_data/sep_train',\n",
    "                                                        target_size=(pic_size, pic_size),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "valid_generator = augment_generator.flow_from_directory('database/image_data/sep_valid',\n",
    "                                                        target_size=(pic_size, pic_size),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break\n",
    "train_sample = train_generator.samples\n",
    "valid_sample = valid_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/72, Model_0-0-0-0 done. Process time == 488s == 0H 8m 8s\n",
      "2/72, Model_0-0-0-1 done. Process time == 1002s == 0H 16m 42s\n",
      "3/72, Model_0-0-0-2 done. Process time == 1492s == 0H 24m 52s\n",
      "4/72, Model_0-0-0-3 done. Process time == 2002s == 0H 33m 22s\n",
      "5/72, Model_0-0-0-4 done. Process time == 2490s == 0H 41m 30s\n",
      "6/72, Model_0-0-0-5 done. Process time == 2992s == 0H 49m 52s\n",
      "7/72, Model_0-0-1-0 done. Process time == 3481s == 0H 58m 1s\n",
      "8/72, Model_0-0-1-1 done. Process time == 3989s == 1H 6m 29s\n",
      "9/72, Model_0-0-1-2 done. Process time == 4481s == 1H 14m 41s\n",
      "10/72, Model_0-0-1-3 done. Process time == 4994s == 1H 23m 14s\n",
      "11/72, Model_0-0-1-4 done. Process time == 5482s == 1H 31m 22s\n",
      "12/72, Model_0-0-1-5 done. Process time == 5985s == 1H 39m 45s\n",
      "13/72, Model_0-1-0-0 done. Process time == 6477s == 1H 47m 57s\n",
      "14/72, Model_0-1-0-1 done. Process time == 6996s == 1H 56m 36s\n",
      "15/72, Model_0-1-0-2 done. Process time == 7491s == 2H 4m 51s\n",
      "16/72, Model_0-1-0-3 done. Process time == 8008s == 2H 13m 28s\n",
      "17/72, Model_0-1-0-4 done. Process time == 8506s == 2H 21m 46s\n",
      "18/72, Model_0-1-0-5 done. Process time == 9021s == 2H 30m 21s\n",
      "19/72, Model_0-1-1-0 done. Process time == 9520s == 2H 38m 40s\n",
      "20/72, Model_0-1-1-1 done. Process time == 10045s == 2H 47m 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/72, Model_0-1-1-2 done. Process time == 10553s == 2H 55m 53s\n"
     ]
    }
   ],
   "source": [
    "loop_start = time.time()\n",
    "count = 0\n",
    "\n",
    "for i in range(len(Conv2D_size)):\n",
    "    for j in range(len(drop_out)):\n",
    "        for k in range(len(l1_ratio)):\n",
    "            for m in range(len(optimizer)):\n",
    "                model_name = f'Model_{Conv2D_size[i]}-{drop_out[j]}-{l1_ratio[k]}-{optimizer[m]}'\n",
    "                model = create_model(model_name, Conv2D_size[i], pic_size, l1_ratio[k], pool_size, drop_out[j])\n",
    "                create_compile(optimizer[m])\n",
    "                history = model.fit(train_generator, epochs=epochs, verbose=0,\n",
    "                                    steps_per_epoch=int(train_sample/batch_size),\n",
    "                                    validation_data=valid_generator,\n",
    "                                    validation_steps=int(valid_sample/batch_size))\n",
    "                id_li = []\n",
    "                flower_class = []\n",
    "                for n in range(len(list(unknown_dict.keys()))):\n",
    "                    serial = list(unknown_dict.keys())[n]\n",
    "                    pred = model.predict(unknown_dict[serial])[0]\n",
    "                    id_li.append(serial)\n",
    "                    flower_class.append(list(pred).index(max(pred)))\n",
    "                    pred_result_df = pd.DataFrame(columns=['id', 'flower_class'])\n",
    "                    pred_result_df['id'] = id_li\n",
    "                    pred_result_df['flower_class'] = flower_class\n",
    "                pred_result_df['flower_class'].value_counts().sort_index()\n",
    "                pred_result_df.to_csv(f'model/FS_{fn_serial}/pred_result_FS_{i}-{j}-{k}-{m}.csv', index=False)\n",
    "                train_acc = model.history.history[\"accuracy\"]\n",
    "                valid_acc = model.history.history[\"val_accuracy\"]\n",
    "                np.save(f'model/FS_{fn_serial}/History_{i}-{j}-{k}-{m}.npy', [train_acc, valid_acc])\n",
    "                plt.figure(figsize=(10,8))\n",
    "                plt.title(f'Accuracy_{i}-{j}-{k}-{m}')\n",
    "                plt.ylim([0, 1])\n",
    "                plt.xlim([0, 50])\n",
    "                plt.plot(train_acc, label = 'train_acc')\n",
    "                plt.plot(valid_acc, label = 'valid_acc')\n",
    "                plt.legend()\n",
    "                plt.savefig(f'model/FS_{fn_serial}/Accuracy_{i}-{j}-{k}-{m}.png')\n",
    "                plt.clf()\n",
    "                count += 1\n",
    "                print(f'{count}/{total_item}, Model_{i}-{j}-{k}-{m} done. {happy_time(loop_start, time.time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
