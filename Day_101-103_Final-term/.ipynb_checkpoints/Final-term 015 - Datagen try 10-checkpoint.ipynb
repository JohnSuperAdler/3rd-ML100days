{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### DNN module\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.applications import ResNet50\n",
    "from keras.optimizers import Adagrad, RMSprop, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Common moldule\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 5 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 20 # 訓練的 epochs 數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_size = 120\n",
    "fn_serial = '014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratio = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 120, 120, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 120, 120, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 60, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 128)       36992     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               803328    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 936,037\n",
      "Trainable params: 936,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(pic_size, pic_size, 3), kernel_regularizer=l1(l1_ratio)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l1(l1_ratio)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l1(l1_ratio)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l1(l1_ratio)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_regularizer=l1(l1_ratio)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_generator = ImageDataGenerator(\n",
    "                                       rotation_range=20,\n",
    "                                       rescale=1./255,\n",
    "                                       #featurewise_center=True,\n",
    "                                       #featurewise_std_normalization=True,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       #data_format='channels_last'\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2823 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = augment_generator.flow_from_directory('database/image_data/train',\n",
    "                                                        target_size=(pic_size, pic_size),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2823 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = augment_generator.flow_from_directory('database/image_data/train',\n",
    "                                                        target_size=(pic_size, pic_size),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (64, 120, 120, 3)\n",
      "labels batch shape: (64, 5)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 25s 562ms/step - loss: 1.6224 - accuracy: 0.2983 - val_loss: 1.3778 - val_accuracy: 0.3945\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 23s 533ms/step - loss: 1.3059 - accuracy: 0.4378 - val_loss: 1.2474 - val_accuracy: 0.4932\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 22s 503ms/step - loss: 1.1692 - accuracy: 0.5292 - val_loss: 0.9188 - val_accuracy: 0.5784\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 21s 486ms/step - loss: 1.0710 - accuracy: 0.5788 - val_loss: 1.0676 - val_accuracy: 0.5931\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 21s 486ms/step - loss: 1.0325 - accuracy: 0.5904 - val_loss: 0.8290 - val_accuracy: 0.6382\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 20s 466ms/step - loss: 0.9869 - accuracy: 0.6209 - val_loss: 1.0508 - val_accuracy: 0.6554\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 20s 465ms/step - loss: 0.9366 - accuracy: 0.6357 - val_loss: 0.8690 - val_accuracy: 0.6704\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 21s 478ms/step - loss: 0.9557 - accuracy: 0.6386 - val_loss: 0.7749 - val_accuracy: 0.6459\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 22s 490ms/step - loss: 0.8919 - accuracy: 0.6636 - val_loss: 0.9678 - val_accuracy: 0.7009\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 20s 460ms/step - loss: 0.9084 - accuracy: 0.6578 - val_loss: 0.9352 - val_accuracy: 0.6341\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 21s 477ms/step - loss: 0.8223 - accuracy: 0.6857 - val_loss: 0.8586 - val_accuracy: 0.6440\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 20s 462ms/step - loss: 0.8155 - accuracy: 0.6905 - val_loss: 0.8414 - val_accuracy: 0.7028\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 20s 459ms/step - loss: 0.8244 - accuracy: 0.6865 - val_loss: 0.7034 - val_accuracy: 0.7143\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 20s 455ms/step - loss: 0.7789 - accuracy: 0.7065 - val_loss: 0.7801 - val_accuracy: 0.7289\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 21s 466ms/step - loss: 0.7496 - accuracy: 0.7086 - val_loss: 0.8176 - val_accuracy: 0.6917\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 20s 448ms/step - loss: 0.7539 - accuracy: 0.7184 - val_loss: 0.6233 - val_accuracy: 0.7467\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 21s 478ms/step - loss: 0.7294 - accuracy: 0.7156 - val_loss: 0.7995 - val_accuracy: 0.7178\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 22s 500ms/step - loss: 0.7004 - accuracy: 0.7336 - val_loss: 0.7282 - val_accuracy: 0.7226\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 20s 461ms/step - loss: 0.6937 - accuracy: 0.7379 - val_loss: 0.7680 - val_accuracy: 0.7187\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 21s 474ms/step - loss: 0.7143 - accuracy: 0.7358 - val_loss: 0.7435 - val_accuracy: 0.7665\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=int(2823/batch_size), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'model/STD_datagen_0101_{fn_serial}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Test on unknown sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['database/image_data/test\\\\0028624c49b3e0610ff9f1d111f5d532.jpg',\n",
       " 'database/image_data/test\\\\002c30700185b7971369258b438070d5.jpg',\n",
       " 'database/image_data/test\\\\00852f4f666acecd0c0d140365b42efd.jpg',\n",
       " 'database/image_data/test\\\\00c08828fce04e360c732cac01edad9e.jpg',\n",
       " 'database/image_data/test\\\\00d366e7877b6a78b104b57d67b60e6b.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_unknown = glob.glob('database/image_data/test/*')\n",
    "path_unknown[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleRGI3d(input_mx, resize_to, dtype='float32'):\n",
    "    # Ref: 10 3-A-7\n",
    "    # Ver. 2.1\n",
    "    # input_mx : numpy array, the original target matrix\n",
    "    # resize_to: list or tuple with 3 int inside\n",
    "    a, b, c = np.shape(input_mx)\n",
    "    p, q, r = resize_to\n",
    "    z_grid = np.linspace(0, p - 1, a)\n",
    "    y_grid = np.linspace(0, q - 1, b)\n",
    "    x_grid = np.linspace(0, r - 1, c)\n",
    "    RGI = RegularGridInterpolator((z_grid, y_grid, x_grid), input_mx)\n",
    "    z_grid_t2 = np.arange(p)\n",
    "    y_grid_t2 = np.arange(q)\n",
    "    x_grid_t2 = np.arange(r)\n",
    "    meshgrid_para = np.meshgrid(z_grid_t2, y_grid_t2, x_grid_t2)\n",
    "    RGI_mesh_mx = RGI((meshgrid_para[0], meshgrid_para[1], meshgrid_para[2]))\n",
    "    RGI_mx = np.transpose(RGI_mesh_mx, axes=[1, 0, 2]).astype(dtype)\n",
    "    return RGI_mx\n",
    "\n",
    "def happy_time(start,stop):\n",
    "    process_time = round(stop - start)\n",
    "    ss = process_time % 60\n",
    "    mm = process_time // 60 % 60\n",
    "    hh = process_time // 3600\n",
    "    duration = \"Process time == {}s == {}H {}m {}s\".format(process_time,hh,mm,ss)\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 files done. Process time == 3s == 0H 0m 3s\n",
      "400 files done. Process time == 6s == 0H 0m 6s\n",
      "600 files done. Process time == 9s == 0H 0m 9s\n",
      "800 files done. Process time == 12s == 0H 0m 12s\n",
      "1000 files done. Process time == 15s == 0H 0m 15s\n",
      "1200 files done. Process time == 18s == 0H 0m 18s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "id_li = []\n",
    "flower_class = []\n",
    "loop_start = time.time()\n",
    "\n",
    "for j in range(len(path_unknown)):\n",
    "    serial = os.path.basename(path_unknown[j])[:-4]\n",
    "    temp_pic = np.asarray(Image.open(path_unknown[j]))\n",
    "    temp_pic = resampleRGI3d(temp_pic, (pic_size, pic_size, 3))\n",
    "    temp_shape = np.shape(temp_pic)\n",
    "    temp_pic = np.expand_dims(temp_pic, axis = 0)\n",
    "    pred = model.predict(temp_pic)[0]\n",
    "    id_li.append(serial)\n",
    "    flower_class.append(list(pred).index(max(pred)))\n",
    "    if (j+1) % 200 == 0:\n",
    "        print(j+1, 'files done.', happy_time(loop_start, time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result_df = pd.DataFrame(columns=['id', 'flower_class'])\n",
    "pred_result_df['id'] = id_li\n",
    "pred_result_df['flower_class'] = flower_class\n",
    "pred_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result_df['flower_class'].value_counts().sort_index()\n",
    "\n",
    "#0    574\n",
    "#1      3\n",
    "#2    196\n",
    "#3    687\n",
    "#4    540\n",
    "#Name: flower_class, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result_df.to_csv(f'model/pred_result_STD_datagen_0101_{fn_serial}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#####\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
