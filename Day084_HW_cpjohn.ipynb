{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "### 請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout: 0.25, 0.1\n",
    "# regularizers: L1, L2\n",
    "# batch-normalization: True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\", \"c\", \"orange\"]\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95\n",
    "reg_ratio = [1e-4, 1e-8]\n",
    "drop_ratio = [0.1, 0.25]\n",
    "batch_n = [True, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_l1(input_shape, output_units=10, num_neurons=[512, 256, 128], drop_ratio=0.2, l_ratio=0.0001, bn=True):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=l1(l_ratio))(input_layer)\n",
    "            x = Dropout(drop_ratio)(x)\n",
    "            if bn:\n",
    "                x = BatchNormalization()(x)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=l1(l_ratio))(x)\n",
    "            x = Dropout(drop_ratio)(x)\n",
    "            if bn:\n",
    "                x = BatchNormalization()(x)\n",
    "            else:\n",
    "                pass\n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 6.0744 - accuracy: 0.2901 - val_loss: 5.7342 - val_accuracy: 0.3654\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 5.6817 - accuracy: 0.3750 - val_loss: 5.5121 - val_accuracy: 0.4197\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 5.5113 - accuracy: 0.4084 - val_loss: 5.3976 - val_accuracy: 0.4279\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 5.3891 - accuracy: 0.4275 - val_loss: 5.2968 - val_accuracy: 0.4394\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 5.2764 - accuracy: 0.4424 - val_loss: 5.2052 - val_accuracy: 0.4568\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 5.1849 - accuracy: 0.4531 - val_loss: 5.1610 - val_accuracy: 0.4506\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 5.0926 - accuracy: 0.4656 - val_loss: 5.0533 - val_accuracy: 0.4670\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 5.0068 - accuracy: 0.4721 - val_loss: 5.0034 - val_accuracy: 0.4671\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 4.9298 - accuracy: 0.4778 - val_loss: 4.9525 - val_accuracy: 0.4618\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.8482 - accuracy: 0.4859 - val_loss: 4.8552 - val_accuracy: 0.4673\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.7767 - accuracy: 0.4898 - val_loss: 4.7753 - val_accuracy: 0.4788\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.6916 - accuracy: 0.4989 - val_loss: 4.6817 - val_accuracy: 0.4896\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.6168 - accuracy: 0.5044 - val_loss: 4.6474 - val_accuracy: 0.4831\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.5463 - accuracy: 0.5079 - val_loss: 4.5717 - val_accuracy: 0.4915\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.4758 - accuracy: 0.5109 - val_loss: 4.5417 - val_accuracy: 0.4766\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.4119 - accuracy: 0.5147 - val_loss: 4.5548 - val_accuracy: 0.4545\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.3366 - accuracy: 0.5197 - val_loss: 4.4465 - val_accuracy: 0.4689\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.2893 - accuracy: 0.5171 - val_loss: 4.3725 - val_accuracy: 0.4802\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 4.2248 - accuracy: 0.5193 - val_loss: 4.3610 - val_accuracy: 0.4643\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 4.1716 - accuracy: 0.5219 - val_loss: 4.2955 - val_accuracy: 0.4593\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.1103 - accuracy: 0.5231 - val_loss: 4.1845 - val_accuracy: 0.4891\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 4.0512 - accuracy: 0.5260 - val_loss: 4.1357 - val_accuracy: 0.4870\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.9882 - accuracy: 0.5327 - val_loss: 4.0938 - val_accuracy: 0.4871\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.9400 - accuracy: 0.5277 - val_loss: 4.0474 - val_accuracy: 0.4820\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.8703 - accuracy: 0.5333 - val_loss: 4.0786 - val_accuracy: 0.4450\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.8279 - accuracy: 0.5316 - val_loss: 4.0483 - val_accuracy: 0.4495\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.7671 - accuracy: 0.5371 - val_loss: 3.9561 - val_accuracy: 0.4561\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 3.7088 - accuracy: 0.5372 - val_loss: 3.7888 - val_accuracy: 0.5037\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.6677 - accuracy: 0.5370 - val_loss: 3.8200 - val_accuracy: 0.4756\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.6181 - accuracy: 0.5351 - val_loss: 3.7420 - val_accuracy: 0.4876\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.5793 - accuracy: 0.5334 - val_loss: 3.7852 - val_accuracy: 0.4678\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.5332 - accuracy: 0.5346 - val_loss: 3.6290 - val_accuracy: 0.4988\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.4820 - accuracy: 0.5354 - val_loss: 3.6359 - val_accuracy: 0.4731\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.4256 - accuracy: 0.5420 - val_loss: 3.6303 - val_accuracy: 0.4563\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.3875 - accuracy: 0.5379 - val_loss: 3.4603 - val_accuracy: 0.5079\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.3362 - accuracy: 0.5371 - val_loss: 3.4346 - val_accuracy: 0.5068\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.2750 - accuracy: 0.5470 - val_loss: 3.5042 - val_accuracy: 0.4612\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 3.2352 - accuracy: 0.5461 - val_loss: 3.4070 - val_accuracy: 0.4782\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.1987 - accuracy: 0.5427 - val_loss: 3.3789 - val_accuracy: 0.4780\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 3.1519 - accuracy: 0.5475 - val_loss: 3.3225 - val_accuracy: 0.4766\n",
      "Epoch 41/50\n",
      "25856/50000 [==============>...............] - ETA: 0s - loss: 3.1072 - accuracy: 0.5512"
     ]
    }
   ],
   "source": [
    "results_l1 = {}\n",
    "\n",
    "for i in drop_ratio:\n",
    "    for j in reg_ratio:\n",
    "        for k in batch_n:\n",
    "            model = build_mlp_l1(input_shape=x_train.shape[1:], drop_ratio=i, l_ratio=j, bn=k)\n",
    "            model.summary()\n",
    "            optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "            model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "            model.fit(x_train, y_train, \n",
    "                      epochs=EPOCHS, \n",
    "                      batch_size=BATCH_SIZE, \n",
    "                      validation_data=(x_test, y_test), \n",
    "                      shuffle=True)\n",
    "            # Collect results\n",
    "            train_loss = model.history.history[\"loss\"]\n",
    "            valid_loss = model.history.history[\"val_loss\"]\n",
    "            train_acc = model.history.history[\"accuracy\"]\n",
    "            valid_acc = model.history.history[\"val_accuracy\"]\n",
    "            exp_name_tag = f'drp_{str(i)}_reg_{str(j)}_bn_{str(k)}'\n",
    "            results_l1[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                        'valid-loss': valid_loss,\n",
    "                                        'train-acc': train_acc,\n",
    "                                        'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results_l1.keys()):\n",
    "    plt.plot(range(len(results_l1[cond]['train-loss'])),results_l1[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results_l1[cond]['valid-loss'])),results_l1[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.ylim([0.5, 2.5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results_l1.keys()):\n",
    "    plt.plot(range(len(results_l1[cond]['train-acc'])),results_l1[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results_l1[cond]['valid-acc'])),results_l1[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_l2(input_shape, output_units=10, num_neurons=[512, 256, 128], drop_ratio=0.2, l_ratio=0.0001, bn=True):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=l2(l_ratio))(input_layer)\n",
    "            x = Dropout(drp_ratio)(x)\n",
    "            if bn:\n",
    "                x = BatchNormalization()(x)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=l2(l1_ratio))(x)\n",
    "            x = Dropout(drp_ratio)(x)\n",
    "            if bn:\n",
    "                x = BatchNormalization()(x)\n",
    "            else:\n",
    "                pass\n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_l2 = {}\n",
    "\n",
    "for i in drop_ratio:\n",
    "    for j in reg_ratio:\n",
    "        for k in batch_n:\n",
    "            model = build_mlp_l2(input_shape=x_train.shape[1:], drop_ratio=i, l_ratio=j, bn=k)\n",
    "            model.summary()\n",
    "            optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "            model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "            model.fit(x_train, y_train, \n",
    "                      epochs=EPOCHS, \n",
    "                      batch_size=BATCH_SIZE, \n",
    "                      validation_data=(x_test, y_test), \n",
    "                      shuffle=True)\n",
    "            # Collect results\n",
    "            train_loss = model.history.history[\"loss\"]\n",
    "            valid_loss = model.history.history[\"val_loss\"]\n",
    "            train_acc = model.history.history[\"accuracy\"]\n",
    "            valid_acc = model.history.history[\"val_accuracy\"]\n",
    "            exp_name_tag = f'drp_{str(i)}_reg_{str(j)_bn_{str(k)}}'\n",
    "            results_l2[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                        'valid-loss': valid_loss,\n",
    "                                        'train-acc': train_acc,\n",
    "                                        'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results_l2.keys()):\n",
    "    plt.plot(range(len(results_l2[cond]['train-loss'])),results_l2[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results_l2[cond]['valid-loss'])),results_l2[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.ylim([0.5, 2.5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results_l2.keys()):\n",
    "    plt.plot(range(len(results_l2[cond]['train-acc'])),results_l2[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results_l2[cond]['valid-acc'])),results_l2[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
