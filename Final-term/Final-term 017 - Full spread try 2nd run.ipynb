{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### DNN module\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop, Adagrad, Adam, SGD\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from keras import backend as K\n",
    "#from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Common moldule\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Control Panel\n",
    "\n",
    "fn_serial   = '017'\n",
    "batch_size  = 64\n",
    "num_classes = 5\n",
    "epochs      = 100\n",
    "pic_size    = 120\n",
    "pool_size   = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total config: 72\n"
     ]
    }
   ],
   "source": [
    "##### Selection\n",
    "\n",
    "Conv2D_size = [(3, 3), (5, 5), (7, 7)]\n",
    "drop_out    = [0., 0.1]\n",
    "l2_ratio    = [1e-4, 1e-8]\n",
    "optimizer   = [Adam(lr=0.01),\n",
    "               Adam(lr=0.001),\n",
    "               RMSprop(lr=0.01),\n",
    "               RMSprop(lr=0.001),\n",
    "               SGD(lr=0.01, momentum=0.95),\n",
    "               SGD(lr=0.001, momentum=0.95),\n",
    "              ]\n",
    "\n",
    "total_item = len(Conv2D_size) * len(drop_out) * len(l2_ratio) * len(optimizer)\n",
    "print('Total config:', total_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Note \n",
    "\n",
    "#Conv2D_size = [(3, 3), (5, 5), (7, 7)]\n",
    "#drop_out    = [0., 0.1]\n",
    "#l2_ratio    = [1e-4, 1e-8]\n",
    "#optimizer   = [Adam(lr=0.01),\n",
    "#               Adam(lr=0.001),\n",
    "#               RMSprop(lr=0.01),\n",
    "#               RMSprop(lr=0.001),\n",
    "#               SGD(lr=0.01, momentum=0.95),\n",
    "#               SGD(lr=0.001, momentum=0.95),\n",
    "#              ]\n",
    "\n",
    "# Good result:\n",
    "# 0013 0103 0104 0113 0114 1013 1014 1015 1104 1105 1115 2004\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, Conv2D_size, pic_size, l2_ratio, pool_size, drop_out_ratio):\n",
    "    model = Sequential()\n",
    "    model.name=model_name\n",
    "    model.add(Conv2D(32, Conv2D_size, padding='same', input_shape=(pic_size, pic_size, 3), kernel_regularizer=l2(l2_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Conv2D(128, Conv2D_size, padding='same', kernel_regularizer=l2(l2_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Conv2D(64, Conv2D_size, padding='same', kernel_regularizer=l2(l2_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Conv2D(32, Conv2D_size, padding='same', kernel_regularizer=l2(l2_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=l2(l2_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compile(optimizer):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleRGI3d(input_mx, resize_to, dtype='float32'):\n",
    "    # Ref: 10 3-A-7\n",
    "    # Ver. 2.1\n",
    "    # input_mx : numpy array, the original target matrix\n",
    "    # resize_to: list or tuple with 3 int inside\n",
    "    a, b, c = np.shape(input_mx)\n",
    "    p, q, r = resize_to\n",
    "    z_grid = np.linspace(0, p - 1, a)\n",
    "    y_grid = np.linspace(0, q - 1, b)\n",
    "    x_grid = np.linspace(0, r - 1, c)\n",
    "    RGI = RegularGridInterpolator((z_grid, y_grid, x_grid), input_mx)\n",
    "    z_grid_t2 = np.arange(p)\n",
    "    y_grid_t2 = np.arange(q)\n",
    "    x_grid_t2 = np.arange(r)\n",
    "    meshgrid_para = np.meshgrid(z_grid_t2, y_grid_t2, x_grid_t2)\n",
    "    RGI_mesh_mx = RGI((meshgrid_para[0], meshgrid_para[1], meshgrid_para[2]))\n",
    "    RGI_mx = np.transpose(RGI_mesh_mx, axes=[1, 0, 2]).astype(dtype)\n",
    "    return RGI_mx\n",
    "\n",
    "def happy_time(start,stop):\n",
    "    process_time = round(stop - start)\n",
    "    ss = process_time % 60\n",
    "    mm = process_time // 60 % 60\n",
    "    hh = process_time // 3600\n",
    "    duration = \"Process time == {}s == {}H {}m {}s\".format(process_time,hh,mm,ss)\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unknown = glob.glob('database/image_data/test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dict: 2000\n"
     ]
    }
   ],
   "source": [
    "unknown_dict = {}\n",
    "\n",
    "for j in range(len(path_unknown)):\n",
    "    serial = os.path.basename(path_unknown[j])[:-4]\n",
    "    temp_pic = np.asarray(Image.open(path_unknown[j]))\n",
    "    temp_pic = resampleRGI3d(temp_pic, (pic_size, pic_size, 3))\n",
    "    temp_shape = np.shape(temp_pic)\n",
    "    temp_pic = np.expand_dims(temp_pic, axis = 0)\n",
    "    unknown_dict[serial] = temp_pic\n",
    "\n",
    "print('Length of dict:', len(list(unknown_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ImageDataGenerator\n",
    "\n",
    "augment_generator = ImageDataGenerator(\n",
    "                                       rotation_range=20,\n",
    "                                       rescale=1./255,\n",
    "                                       #featurewise_center=True,\n",
    "                                       #featurewise_std_normalization=True,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       #data_format='channels_last'\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2323 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n",
      "data batch shape: (64, 120, 120, 3)\n",
      "labels batch shape: (64, 5)\n"
     ]
    }
   ],
   "source": [
    "##### Generator for train and validation\n",
    "\n",
    "train_generator = augment_generator.flow_from_directory('database/image_data/sep_train',\n",
    "                                                        target_size=(pic_size, pic_size),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "valid_generator = augment_generator.flow_from_directory('database/image_data/sep_valid',\n",
    "                                                        target_size=(pic_size, pic_size),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break\n",
    "train_sample = train_generator.samples\n",
    "valid_sample = valid_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Note \n",
    "\n",
    "#Conv2D_size = [(3, 3), (5, 5), (7, 7)]\n",
    "#drop_out    = [0., 0.1]\n",
    "#l2_ratio    = [1e-4, 1e-8]\n",
    "#optimizer   = [Adam(lr=0.01),\n",
    "#               Adam(lr=0.001),\n",
    "#               RMSprop(lr=0.01),\n",
    "#               RMSprop(lr=0.001),\n",
    "#               SGD(lr=0.01, momentum=0.95),\n",
    "#               SGD(lr=0.001, momentum=0.95),\n",
    "#              ]\n",
    "\n",
    "# Good result:\n",
    "# 0013 0103 0104 0113 0114 1013 1014 1015 1104 1105 1115 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/72, Model_0-1-0-4 done. Process time == 985s == 0H 16m 25s\n",
      "2/72, Model_0-1-1-3 done. Process time == 1974s == 0H 32m 54s\n",
      "3/72, Model_0-1-1-4 done. Process time == 2959s == 0H 49m 19s\n",
      "4/72, Model_1-0-1-3 done. Process time == 3944s == 1H 5m 44s\n",
      "5/72, Model_1-0-1-4 done. Process time == 4927s == 1H 22m 7s\n",
      "6/72, Model_1-0-1-5 done. Process time == 5915s == 1H 38m 35s\n",
      "7/72, Model_1-1-0-4 done. Process time == 6907s == 1H 55m 7s\n",
      "8/72, Model_1-1-0-5 done. Process time == 7902s == 2H 11m 42s\n",
      "9/72, Model_1-1-1-5 done. Process time == 8894s == 2H 28m 14s\n",
      "10/72, Model_2-0-0-4 done. Process time == 9886s == 2H 44m 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loop_start = time.time()\n",
    "count = 0\n",
    "\n",
    "for i in range(len(Conv2D_size)):\n",
    "    for j in range(len(drop_out)):\n",
    "        for k in range(len(l2_ratio)):\n",
    "            for m in range(len(optimizer)):\n",
    "                if (m == 0) or (m == 1) or (m == 2):\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "                #if   (i == 0) and (j == 0) and (k == 1) and (m == 3): pass\n",
    "                #elif (i == 0) and (j == 1) and (k == 0) and (m == 3): pass\n",
    "                if (i == 0) and (j == 1) and (k == 0) and (m == 4): pass\n",
    "                elif (i == 0) and (j == 1) and (k == 1) and (m == 3): pass\n",
    "                elif (i == 0) and (j == 1) and (k == 1) and (m == 4): pass\n",
    "                elif (i == 1) and (j == 0) and (k == 1) and (m == 3): pass\n",
    "                elif (i == 1) and (j == 0) and (k == 1) and (m == 4): pass\n",
    "                elif (i == 1) and (j == 0) and (k == 1) and (m == 5): pass\n",
    "                elif (i == 1) and (j == 1) and (k == 0) and (m == 4): pass\n",
    "                elif (i == 1) and (j == 1) and (k == 0) and (m == 5): pass\n",
    "                elif (i == 1) and (j == 1) and (k == 1) and (m == 5): pass\n",
    "                elif (i == 2) and (j == 0) and (k == 0) and (m == 4): pass\n",
    "                else: continue\n",
    "                model_name = f'Model_{Conv2D_size[i]}-{drop_out[j]}-{l2_ratio[k]}-{optimizer[m]}'\n",
    "                model = create_model(model_name, Conv2D_size[i], pic_size, l2_ratio[k], pool_size, drop_out[j])\n",
    "                create_compile(optimizer[m])\n",
    "                history = model.fit(train_generator, epochs=epochs, verbose=0,\n",
    "                                    steps_per_epoch=int(train_sample/batch_size),\n",
    "                                    validation_data=valid_generator,\n",
    "                                    validation_steps=int(valid_sample/batch_size))\n",
    "                id_li = []\n",
    "                flower_class = []\n",
    "                for n in range(len(list(unknown_dict.keys()))):\n",
    "                    serial = list(unknown_dict.keys())[n]\n",
    "                    pred = model.predict(unknown_dict[serial])[0]\n",
    "                    id_li.append(serial)\n",
    "                    flower_class.append(list(pred).index(max(pred)))\n",
    "                    pred_result_df = pd.DataFrame(columns=['id', 'flower_class'])\n",
    "                    pred_result_df['id'] = id_li\n",
    "                    pred_result_df['flower_class'] = flower_class\n",
    "                pred_result_df['flower_class'].value_counts().sort_index()\n",
    "                pred_result_df.to_csv(f'model/FS_{fn_serial}/pred_result_FS_{i}-{j}-{k}-{m}.csv', index=False)\n",
    "                train_acc = model.history.history[\"accuracy\"]\n",
    "                valid_acc = model.history.history[\"val_accuracy\"]\n",
    "                np.save(f'model/FS_{fn_serial}/History_{i}-{j}-{k}-{m}.npy', [train_acc, valid_acc])\n",
    "                plt.figure(figsize=(10,8))\n",
    "                plt.title(f'Accuracy_{i}-{j}-{k}-{m}')\n",
    "                plt.ylim([0, 1])\n",
    "                plt.xlim([0, 100])\n",
    "                plt.plot(train_acc, label = 'train_acc')\n",
    "                plt.plot(valid_acc, label = 'valid_acc')\n",
    "                plt.legend()\n",
    "                plt.savefig(f'model/FS_{fn_serial}/Accuracy_{i}-{j}-{k}-{m}.png')\n",
    "                plt.clf()\n",
    "                count += 1\n",
    "                print(f'{count}/{total_item}, Model_{i}-{j}-{k}-{m} done. {happy_time(loop_start, time.time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
