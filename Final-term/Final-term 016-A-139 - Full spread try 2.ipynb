{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### DNN module\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop, Adagrad, Adam, SGD\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from keras import backend as K\n",
    "#from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Common moldule\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Control Panel\n",
    "\n",
    "fn_serial   = '016-A'\n",
    "batch_size  = 64\n",
    "num_classes = 5\n",
    "epochs      = 50\n",
    "pic_size    = 120\n",
    "pool_size   = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total config: 72\n"
     ]
    }
   ],
   "source": [
    "##### Selection\n",
    "\n",
    "Conv2D_size = [(3, 3), (5, 5), (7, 7)]\n",
    "drop_out    = [0., 0.1]\n",
    "l1_ratio    = [1e-4, 1e-8]\n",
    "optimizer   = [Adam(lr=0.01),\n",
    "               Adam(lr=0.001),\n",
    "               RMSprop(lr=0.01),\n",
    "               RMSprop(lr=0.001),\n",
    "               SGD(lr=0.01, momentum=0.95),\n",
    "               SGD(lr=0.001, momentum=0.95),\n",
    "              ]\n",
    "\n",
    "total_item = len(Conv2D_size) * len(drop_out) * len(l1_ratio) * len(optimizer)\n",
    "print('Total config:', total_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, Conv2D_size, pic_size, l1_ratio, pool_size, drop_out_ratio):\n",
    "    model = Sequential()\n",
    "    model.name=model_name\n",
    "    model.add(Conv2D(32, Conv2D_size, padding='same', input_shape=(pic_size, pic_size, 3), kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Conv2D(128, Conv2D_size, padding='same', kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Conv2D(64, Conv2D_size, padding='same', kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Conv2D(32, Conv2D_size, padding='same', kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=l1(l1_ratio)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_out_ratio))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compile(optimizer):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleRGI3d(input_mx, resize_to, dtype='float32'):\n",
    "    # Ref: 10 3-A-7\n",
    "    # Ver. 2.1\n",
    "    # input_mx : numpy array, the original target matrix\n",
    "    # resize_to: list or tuple with 3 int inside\n",
    "    a, b, c = np.shape(input_mx)\n",
    "    p, q, r = resize_to\n",
    "    z_grid = np.linspace(0, p - 1, a)\n",
    "    y_grid = np.linspace(0, q - 1, b)\n",
    "    x_grid = np.linspace(0, r - 1, c)\n",
    "    RGI = RegularGridInterpolator((z_grid, y_grid, x_grid), input_mx)\n",
    "    z_grid_t2 = np.arange(p)\n",
    "    y_grid_t2 = np.arange(q)\n",
    "    x_grid_t2 = np.arange(r)\n",
    "    meshgrid_para = np.meshgrid(z_grid_t2, y_grid_t2, x_grid_t2)\n",
    "    RGI_mesh_mx = RGI((meshgrid_para[0], meshgrid_para[1], meshgrid_para[2]))\n",
    "    RGI_mx = np.transpose(RGI_mesh_mx, axes=[1, 0, 2]).astype(dtype)\n",
    "    return RGI_mx\n",
    "\n",
    "def happy_time(start,stop):\n",
    "    process_time = round(stop - start)\n",
    "    ss = process_time % 60\n",
    "    mm = process_time // 60 % 60\n",
    "    hh = process_time // 3600\n",
    "    duration = \"Process time == {}s == {}H {}m {}s\".format(process_time,hh,mm,ss)\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unknown = glob.glob('database/image_data/test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dict: 2000\n"
     ]
    }
   ],
   "source": [
    "unknown_dict = {}\n",
    "\n",
    "for j in range(len(path_unknown)):\n",
    "    serial = os.path.basename(path_unknown[j])[:-4]\n",
    "    temp_pic = np.asarray(Image.open(path_unknown[j]))\n",
    "    temp_pic = resampleRGI3d(temp_pic, (pic_size, pic_size, 3))\n",
    "    temp_shape = np.shape(temp_pic)\n",
    "    temp_pic = np.expand_dims(temp_pic, axis = 0)\n",
    "    unknown_dict[serial] = temp_pic\n",
    "\n",
    "print('Length of dict:', len(list(unknown_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ImageDataGenerator\n",
    "\n",
    "augment_generator = ImageDataGenerator(\n",
    "                                       rotation_range=20,\n",
    "                                       rescale=1./255,\n",
    "                                       #featurewise_center=True,\n",
    "                                       #featurewise_std_normalization=True,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       #data_format='channels_last'\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2323 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n",
      "data batch shape: (64, 120, 120, 3)\n",
      "labels batch shape: (64, 5)\n"
     ]
    }
   ],
   "source": [
    "##### Generator for train and validation\n",
    "\n",
    "train_generator = augment_generator.flow_from_directory('database/image_data/sep_train',\n",
    "                                                        target_size=(pic_size, pic_size),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "valid_generator = augment_generator.flow_from_directory('database/image_data/sep_valid',\n",
    "                                                        target_size=(pic_size, pic_size),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break\n",
    "train_sample = train_generator.samples\n",
    "valid_sample = valid_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/72, Model_0-1-1-4 done. Process time == 500s == 0H 8m 20s\n",
      "24/72, Model_0-1-1-5 done. Process time == 1017s == 0H 16m 57s\n",
      "26/72, Model_1-0-0-1 done. Process time == 1519s == 0H 25m 19s\n",
      "28/72, Model_1-0-0-3 done. Process time == 2032s == 0H 33m 52s\n",
      "29/72, Model_1-0-0-4 done. Process time == 2519s == 0H 41m 59s\n",
      "30/72, Model_1-0-0-5 done. Process time == 3032s == 0H 50m 32s\n",
      "32/72, Model_1-0-1-1 done. Process time == 3526s == 0H 58m 46s\n",
      "34/72, Model_1-0-1-3 done. Process time == 4039s == 1H 7m 19s\n",
      "35/72, Model_1-0-1-4 done. Process time == 4530s == 1H 15m 30s\n",
      "36/72, Model_1-0-1-5 done. Process time == 5044s == 1H 24m 4s\n",
      "38/72, Model_1-1-0-1 done. Process time == 5549s == 1H 32m 29s\n",
      "40/72, Model_1-1-0-3 done. Process time == 6091s == 1H 41m 31s\n",
      "41/72, Model_1-1-0-4 done. Process time == 6597s == 1H 49m 57s\n",
      "42/72, Model_1-1-0-5 done. Process time == 7133s == 1H 58m 53s\n",
      "44/72, Model_1-1-1-1 done. Process time == 7652s == 2H 7m 32s\n",
      "46/72, Model_1-1-1-3 done. Process time == 8190s == 2H 16m 30s\n",
      "47/72, Model_1-1-1-4 done. Process time == 8701s == 2H 25m 1s\n",
      "48/72, Model_1-1-1-5 done. Process time == 9251s == 2H 34m 11s\n",
      "50/72, Model_2-0-0-1 done. Process time == 9756s == 2H 42m 36s\n",
      "52/72, Model_2-0-0-3 done. Process time == 10290s == 2H 51m 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpjohn\\.conda\\envs\\cpjohn\\lib\\site-packages\\ipykernel_launcher.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/72, Model_2-0-0-4 done. Process time == 10800s == 3H 0m 0s\n",
      "54/72, Model_2-0-0-5 done. Process time == 11329s == 3H 8m 49s\n",
      "56/72, Model_2-0-1-1 done. Process time == 11829s == 3H 17m 9s\n",
      "58/72, Model_2-0-1-3 done. Process time == 12366s == 3H 26m 6s\n",
      "59/72, Model_2-0-1-4 done. Process time == 12868s == 3H 34m 28s\n",
      "60/72, Model_2-0-1-5 done. Process time == 13402s == 3H 43m 22s\n",
      "62/72, Model_2-1-0-1 done. Process time == 13924s == 3H 52m 4s\n",
      "64/72, Model_2-1-0-3 done. Process time == 14464s == 4H 1m 4s\n",
      "65/72, Model_2-1-0-4 done. Process time == 14989s == 4H 9m 49s\n",
      "66/72, Model_2-1-0-5 done. Process time == 15549s == 4H 19m 9s\n",
      "68/72, Model_2-1-1-1 done. Process time == 16069s == 4H 27m 49s\n",
      "70/72, Model_2-1-1-3 done. Process time == 16620s == 4H 37m 0s\n",
      "71/72, Model_2-1-1-4 done. Process time == 17143s == 4H 45m 43s\n",
      "72/72, Model_2-1-1-5 done. Process time == 17698s == 4H 54m 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loop_start = time.time()\n",
    "count = 0\n",
    "\n",
    "for i in range(len(Conv2D_size)):\n",
    "    for j in range(len(drop_out)):\n",
    "        for k in range(len(l1_ratio)):\n",
    "            for m in range(len(optimizer)):\n",
    "                if (m==0) or (m==2):\n",
    "                    count += 1\n",
    "                    continue\n",
    "                if count <= 21:\n",
    "                    count += 1\n",
    "                    continue\n",
    "                model_name = f'Model_{Conv2D_size[i]}-{drop_out[j]}-{l1_ratio[k]}-{optimizer[m]}'\n",
    "                model = create_model(model_name, Conv2D_size[i], pic_size, l1_ratio[k], pool_size, drop_out[j])\n",
    "                create_compile(optimizer[m])\n",
    "                history = model.fit(train_generator, epochs=epochs, verbose=0,\n",
    "                                    steps_per_epoch=int(train_sample/batch_size),\n",
    "                                    validation_data=valid_generator,\n",
    "                                    validation_steps=int(valid_sample/batch_size))\n",
    "                id_li = []\n",
    "                flower_class = []\n",
    "                for n in range(len(list(unknown_dict.keys()))):\n",
    "                    serial = list(unknown_dict.keys())[n]\n",
    "                    pred = model.predict(unknown_dict[serial])[0]\n",
    "                    id_li.append(serial)\n",
    "                    flower_class.append(list(pred).index(max(pred)))\n",
    "                    pred_result_df = pd.DataFrame(columns=['id', 'flower_class'])\n",
    "                    pred_result_df['id'] = id_li\n",
    "                    pred_result_df['flower_class'] = flower_class\n",
    "                pred_result_df['flower_class'].value_counts().sort_index()\n",
    "                pred_result_df.to_csv(f'model/FS_{fn_serial}/pred_result_FS_{i}-{j}-{k}-{m}.csv', index=False)\n",
    "                train_acc = model.history.history[\"accuracy\"]\n",
    "                valid_acc = model.history.history[\"val_accuracy\"]\n",
    "                np.save(f'model/FS_{fn_serial}/History_{i}-{j}-{k}-{m}.npy', [train_acc, valid_acc])\n",
    "                plt.figure(figsize=(10,8))\n",
    "                plt.title(f'Accuracy_{i}-{j}-{k}-{m}')\n",
    "                plt.ylim([0, 1])\n",
    "                plt.xlim([0, 50])\n",
    "                plt.plot(train_acc, label = 'train_acc')\n",
    "                plt.plot(valid_acc, label = 'valid_acc')\n",
    "                plt.legend()\n",
    "                plt.savefig(f'model/FS_{fn_serial}/Accuracy_{i}-{j}-{k}-{m}.png')\n",
    "                plt.clf()\n",
    "                count += 1\n",
    "                print(f'{count}/{total_item}, Model_{i}-{j}-{k}-{m} done. {happy_time(loop_start, time.time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
